<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jing Li</title>
  
  <meta name="author" content="Jing Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="data/stu_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jing Li</name>
              </p>
              <p>I am a final-year (2022-2023) Ph.D. student of <a href="https://sist.shanghaitech.edu.cn/">School of Information Science and Technology</a> at <a href="https://www.shanghaitch.edu.cn/">ShanghaiTech University</a>, advised by Prof. <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>.
              </p>
	      <p>I am interested in computer vision and deep learning, especially scene understanding, scene reconstruction, anomaly detection, image generation and image editing, etc.
	      </p>
	      <p>Before that, I received my B.Eng. degree from <a href="https://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics</a> in 2018.
	      </p>
              <p style="text-align:center">
                <a href="mailto:lijing1@shanghaitech.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/JingLi-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=BCjT17sAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lijing1996/">Github</a> &nbsp/&nbsp
	        <a href="https://space.bilibili.com/95252795">Bilibili</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/lijing.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading> (* = co-first author)
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_fra.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9733271">
                <papertitle>Feature Re-Representation and Reliable Pseudo Label Retraining for Cross-Domain Semantic Segmentation</papertitle>
              </a>
              <br>
              <strong>Jing Li</strong>,
              <a href="https://zhoukang.pro/">Kang Zhou</a>,
              <a href="https://shenhanqian.com/">Shenhan Qian</a>,
              <a href="https://wenli-vision.github.io/">Wen Li</a>,
              <a href="http://www.lxduan.info/">Lixin Duan</a>,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2022</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9733271">paper</a>
            </td>
          </tr>

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_tnnls.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9513473">
                <papertitle>Memorizing Structure-texture Correspondence for Image Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://zhoukang.pro/">Kang Zhou*</a>,
              <strong>Jing Li*</strong>,
              <a href="https://svip-lab.github.io/team/xiaoyt.html">Yuting Xiao</a>,
              <a href="http://en.bme.sjtu.edu.cn/show-33-188.html">Jianlong Yang</a>,
              <a href="https://samjcheng.github.io/">Jun Cheng</a>,
              <a href="https://svip-lab.github.io/team/liuwen.html">Wen Liu</a>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://faculty.sustech.edu.cn/liuj/en/">Jiang Liu</a>,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Neural Networks and Learning Systems (<b>T-NNLS</b>)</em>, 2021 <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9513473">paper</a>
            </td>
          </tr>

          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/256_proxy_ano.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9570167/">
                  <papertitle>Proxy-bridged Image Reconstruction Network for Anomaly Detection in Medical Images</papertitle>
                </a>
                <br>
                <a href="https://zhoukang.pro/">Kang Zhou*</a>,
                <strong>Jing Li*</strong>,
                <a href="https://zachluo.github.io/">Weixin Luo</a>,
                Zhengxin Li,
                <a href="http://en.bme.sjtu.edu.cn/show-33-188.html">Jianlong Yang</a>,
                <a href="https://samjcheng.github.io/">Jun Cheng</a>,
                <a href="https://faculty.sustech.edu.cn/liuj/en/">Jiang Liu</a>,
                <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
                <br>
                <em>IEEE Transactions on Medical Imaging (<b>TMI</b>)</em>, 2021 <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9570167/">paper</a>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_RGBD_counting.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper">
                <papertitle>Density Map Regression Guided Detection Network for RGB-D Crowd Counting and Localization</papertitle>
              </a>
              <br>
              <a href="https://dongzelian.com/">Dongze Lian*</a>,
              <strong>Jing Li*</strong>,
              <a href="https://bertjiazheng.github.io/">Jia Zheng</a>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <br>
              <em>IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2019 <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper">paper</a>
              /
              <a href="https://github.com/svip-lab/Locating_Counting_with_a_Depth_Prior">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_RGBD_counting_pami.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9601215">
                <papertitle>Locating and Counting Heads in Crowds With a Depth Prior</papertitle>
              </a>
              <br>
              <a href="https://dongzelian.com/">Dongze Lian</a>,
              Xianing Chen,
              <strong>Jing Li</strong>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2021</em><br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9601215">paper</a>
              /
              <a href="https://github.com/svip-lab/Locating_Counting_with_a_Depth_Prior">code</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_structured3d.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58545-7_30">
                <papertitle>Structured3D: A Large Photo-Realistic Dataset for Structured 3D Modeling</papertitle>
              </a>
              <br>
              <a href="https://bertjiazheng.github.io/">Jia Zheng</a>,
              Junfei Zhang,
              <strong>Jing Li</strong>,
              Rui Tang,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <a href="https://zihan-z.github.io/">Zihan Zhou</a>
              <br>
              <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2021<br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58545-7_30">paper</a>
              /
              <a href="https://github.com/bertjiazheng/Structured3D">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_partial_anno.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xu_Crowd_Counting_With_Partial_Annotations_in_an_Image_ICCV_2021_paper.html">
                <papertitle>Crowd counting with partial annotations in an image</papertitle>
              </a>
              <br>
              <a href="https://svip-lab.github.io/team/xuyy.html">Yanyu Xu</a>,
              Ziming Zhong,
              <a href="https://dongzelian.com/">Dongze Lian</a>,
              <strong>Jing Li</strong>,
              Zhengxin Li,
              Xinxing Xu,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>
              <br>
              <em>IEEE International Conference on Computer Vision (<b>ICCV</b>)</em>, 2021<br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xu_Crowd_Counting_With_Partial_Annotations_in_an_Image_ICCV_2021_paper.html">paper</a>
              /
              <a href="https://github.com/svip-lab/CrowdCountingPAL">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_video_counting.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220301454">
                <papertitle>Multi-Level Feature Fusion Based Locality-Constrained Spatial Transformer Network for Video Crowd Counting</papertitle>
              </a>
              <br>
              Yanyan Fang,
              <a href="https://sist.shanghaitech.edu.cn/sist_en/2020/0814/c7582a54772/page.htm">Shenghua Gao</a>,
              <strong>Jing Li</strong>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              Linfang He,
              Bo Hu
              <br>
              <em>Neurocomputing </em>, 2019<br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220301454">paper</a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
