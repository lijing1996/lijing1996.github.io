<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jing Li's homepage</title>
  
  <meta name="author" content="Jing Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="data/stu_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jing Li</name>
              </p>
              <p>I am now an AIGC algorithm engineer at <a href="xiaohongshu.com"> Xiaohongshu </a>, also known as RED. I got my Ph.D. degree from <a href="https://sist.shanghaitech.edu.cn/">School of Information Science and Technology</a> at <a href="https://www.shanghaitch.edu.cn/">ShanghaiTech University</a> in 2023, advised by Prof. <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>.
              </p>
<!--               <p>I am interested in computer vision and deep learning, especially scene understanding, scene reconstruction, anomaly detection, image generation and editing, etc.
	      </p> -->
	      <p> I am interested in computer vision and deep learning, especially AIGC, i.e., image generation, 3D generation and video generation. I was interested in scene understanding, scene reconstruction and anomaly detection.
	      </p>
	      <p>Before entering ShanghaiTech University without entrance examination, I received my B.Eng. degree from <a href="https://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics</a> in 2018.
	      </p>
              <p>If you are intersted in finding a job or an internship in Xiaohongshu, feel free to contact me.
          </p>
              <p style="text-align:center">
                <a href="mailto:lijing1@alumni.shanghaitech.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/JingLi-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=BCjT17sAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lijing1996/">Github</a> &nbsp/&nbsp
	        <a href="https://space.bilibili.com/95252795">Bilibili</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/lijing_2023.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading> <bodyfont>(* = co-first author).</bodyfont>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_fra.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9733271">
                <papertitle>Feature Re-Representation and Reliable Pseudo Label Retraining for Cross-Domain Semantic Segmentation</papertitle>
              </a>
              <br>
              <strong>Jing Li</strong>,
              <a href="https://zhoukang.pro/">Kang Zhou</a>,
              <a href="https://shenhanqian.com/">Shenhan Qian</a>,
              <a href="https://wenli-vision.github.io/">Wen Li</a>,
              <a href="http://www.lxduan.info/">Lixin Duan</a>,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2022</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9733271">paper</a>
            </td>
          </tr>

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_tnnls.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9513473">
                <papertitle>Memorizing Structure-texture Correspondence for Image Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://zhoukang.pro/">Kang Zhou*</a>,
              <strong>Jing Li*</strong>,
              <a href="https://svip-lab.github.io/team/xiaoyt.html">Yuting Xiao</a>,
              <a href="http://en.bme.sjtu.edu.cn/show-33-188.html">Jianlong Yang</a>,
              <a href="https://samjcheng.github.io/">Jun Cheng</a>,
              <a href="https://svip-lab.github.io/team/liuwen.html">Wen Liu</a>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://faculty.sustech.edu.cn/liuj/en/">Jiang Liu</a>,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Neural Networks and Learning Systems (<b>T-NNLS</b>)</em>, 2021 <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9513473">paper</a>
            </td>
          </tr>

          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/256_proxy_ano.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9570167/">
                  <papertitle>Proxy-bridged Image Reconstruction Network for Anomaly Detection in Medical Images</papertitle>
                </a>
                <br>
                <a href="https://zhoukang.pro/">Kang Zhou*</a>,
                <strong>Jing Li*</strong>,
                <a href="https://zachluo.github.io/">Weixin Luo</a>,
                Zhengxin Li,
                <a href="http://en.bme.sjtu.edu.cn/show-33-188.html">Jianlong Yang</a>,
                <a href="https://samjcheng.github.io/">Jun Cheng</a>,
                <a href="https://faculty.sustech.edu.cn/liuj/en/">Jiang Liu</a>,
                <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
                <br>
                <em>IEEE Transactions on Medical Imaging (<b>T-MI</b>)</em>, 2021 <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9570167/">paper</a>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_RGBD_counting.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper">
                <papertitle>Density Map Regression Guided Detection Network for RGB-D Crowd Counting and Localization</papertitle>
              </a>
              <br>
              <a href="https://dongzelian.com/">Dongze Lian*</a>,
              <strong>Jing Li*</strong>,
              <a href="https://bertjiazheng.github.io/">Jia Zheng</a>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2019 <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper">paper</a>
              /
              <a href="https://github.com/svip-lab/Locating_Counting_with_a_Depth_Prior">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_roomdesigner.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2310.10027">
                <papertitle>RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=1UD_eBQAAAAJ&hl=en">Yiqun Zhao</a>,
              <a href="https://maikouuu.github.io/">Zibo Zhao</a>,
              <strong>Jing Li</strong>,
              <a href="https://scholar.google.com/citations?user=j71Y2-4AAAAJ&hl=en">Sixun Dong</a>,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>International Conference on 3D Vision (<b>3DV</b>)</em>, 2024<br>
              <a href="https://arxiv.org/pdf/2310.10027">paper</a>
              /
              <a href="https://github.com/zhao-yiqun/RoomDesigner">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_TSP.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wang_TSP-Transformer_Task-Specific_Prompts_Boosted_Transformer_for_Holistic_Scene_Understanding_WACV_2024_paper.pdf">
                <papertitle>TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding</papertitle>
              </a>
              <br>
              <a href="https://github.com/tb2-sy">Shuo Wang</a>,
              <strong>Jing Li</strong>,
              <a href="https://maikouuu.github.io/">Zibo Zhao</a>,
              <a href="https://dongzelian.com">Dongze Lian</a>,
              <a href="https://github.com/hbb1">Binbin Huang</a>,
              Xiaomei Wang,
              Zhengxin Li,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</em>, 2024<br>
              <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wang_TSP-Transformer_Task-Specific_Prompts_Boosted_Transformer_for_Holistic_Scene_Understanding_WACV_2024_paper.pdf">paper</a>
              /
              <a href="https://github.com/tb2-sy/TSP-Transformer">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_RGBD_counting_pami.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9601215">
                <papertitle>Locating and Counting Heads in Crowds With a Depth Prior</papertitle>
              </a>
              <br>
              <a href="https://dongzelian.com/">Dongze Lian</a>,
              Xianing Chen,
              <strong>Jing Li</strong>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2021</em><br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9601215">paper</a>
              /
              <a href="https://github.com/svip-lab/Locating_Counting_with_a_Depth_Prior">code</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_structured3d.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58545-7_30">
                <papertitle>Structured3D: A Large Photo-Realistic Dataset for Structured 3D Modeling</papertitle>
              </a>
              <br>
              <a href="https://bertjiazheng.github.io/">Jia Zheng</a>,
              Junfei Zhang,
              <strong>Jing Li</strong>,
              Rui Tang,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <a href="https://zihan-z.github.io/">Zihan Zhou</a>
              <br>
              <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2020<br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58545-7_30">paper</a>
              /
              <a href="https://github.com/bertjiazheng/Structured3D">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_partial_anno.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xu_Crowd_Counting_With_Partial_Annotations_in_an_Image_ICCV_2021_paper.html">
                <papertitle>Crowd counting with partial annotations in an image</papertitle>
              </a>
              <br>
              <a href="https://svip-lab.github.io/team/xuyy.html">Yanyu Xu</a>,
              <a href="https://scholar.google.com/citations?user=nHG-dw0AAAAJ&hl=en">Ziming Zhong</a>,
              <a href="https://dongzelian.com/">Dongze Lian</a>,
              <strong>Jing Li</strong>,
              Zhengxin Li,
              Xinxing Xu,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>
              <br>
              <em>IEEE International Conference on Computer Vision (<b>ICCV</b>)</em>, 2021<br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xu_Crowd_Counting_With_Partial_Annotations_in_an_Image_ICCV_2021_paper.html">paper</a>
              /
              <a href="https://github.com/svip-lab/CrowdCountingPAL">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/256_video_counting.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220301454">
                <papertitle>Multi-Level Feature Fusion Based Locality-Constrained Spatial Transformer Network for Video Crowd Counting</papertitle>
              </a>
              <br>
              Yanyan Fang,
              <a href="https://scholar.google.com.sg/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a>,
              <strong>Jing Li</strong>,
              <a href="https://zachluo.github.io/">Weixin Luo</a>,
              Linfang He,
              Bo Hu
              <br>
              <em>Neurocomputing </em>, 2019<br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0925231220301454">paper</a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
                <br>
                <script language="JavaScript">
                var LastUpdated = document.lastModified;
                document.writeln ("last updated at " + LastUpdated);
                // End Hiding -->
                </script>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
<html>
<head></head>



<body>

</body>
</html>
</body>

</html>


